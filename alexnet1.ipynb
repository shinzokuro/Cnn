{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet1",
      "provenance": [],
      "authorship_tag": "ABX9TyPAwRtXCvE8iqc1ucaDwgn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinzokuro/Cnn/blob/alex/alexnet1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo9D0M3Mofh_",
        "outputId": "de23645b-4c74-4b9b-b831-3a5634d5775a"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(10))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ntbo9zz2-Um"
      },
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEwmZeD5HRFg"
      },
      "source": [
        "0: airplane\n",
        "1: automobile\n",
        "2: bird\n",
        "3: cat\n",
        "4: deer\n",
        "5: dog\n",
        "6: frog\n",
        "7: horse\n",
        "8: ship\n",
        "9: truck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlAOMFA43CFB",
        "outputId": "f6cfaab0-5970-423a-85ad-a8f8c71e809a"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train),(x_test, y_test)=cifar10.load_data()\n",
        "\n",
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n",
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMODd7mZ4Bz2",
        "outputId": "23836aae-c29d-47d2-b442-3f5dc62480c9"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6H4my5O4HmO"
      },
      "source": [
        "from tensorflow import keras as k"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhSMmqBt4OV2"
      },
      "source": [
        "y_train = k.utils.to_categorical(y_train, num_classes=10)\n",
        "y_val = k.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = k.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecb1Zog73KUx",
        "outputId": "3bc8f70b-b092-4a5f-e3d5-2e5640f6a4f7"
      },
      "source": [
        "\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMQm0uQu4x_r"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJmbOggk5HYI"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr= ReduceLROnPlateau(   monitor='accuracy',   factor=.01,   patience=3,  min_lr=1e-5) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5b7zVTAA8wP"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiPGgXYZ5Ktt"
      },
      "source": [
        "batch_size= 100\n",
        "epochs=100\n",
        "learn_rate=.001"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTHQONVA5OX4",
        "outputId": "cab03e42-71ab-442b-9c70-ba99ea045f1a"
      },
      "source": [
        "AlexNet.fit(train_generator.flow(x_train, y_train, batch_size=batch_size),\n",
        "                      epochs = epochs, \n",
        "                      steps_per_epoch = x_train.shape[0]//batch_size, \n",
        "                      validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size),\n",
        "                      validation_steps = 250, callbacks = [lrr], verbose=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "350/350 [==============================] - ETA: 0s - loss: 1.8118 - accuracy: 0.3406WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "350/350 [==============================] - 76s 81ms/step - loss: 1.8113 - accuracy: 0.3408 - val_loss: 2.4206 - val_accuracy: 0.1963\n",
            "Epoch 2/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.4298 - accuracy: 0.4958\n",
            "Epoch 3/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.2992 - accuracy: 0.5474\n",
            "Epoch 4/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.2081 - accuracy: 0.5840\n",
            "Epoch 5/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.1208 - accuracy: 0.6133\n",
            "Epoch 6/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.0592 - accuracy: 0.6392\n",
            "Epoch 7/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0182 - accuracy: 0.6502\n",
            "Epoch 8/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.9608 - accuracy: 0.6697\n",
            "Epoch 9/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.9238 - accuracy: 0.6828\n",
            "Epoch 10/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.8721 - accuracy: 0.6997\n",
            "Epoch 11/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.8357 - accuracy: 0.7158\n",
            "Epoch 12/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.7975 - accuracy: 0.7309\n",
            "Epoch 13/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.7750 - accuracy: 0.7381\n",
            "Epoch 14/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.7359 - accuracy: 0.7509\n",
            "Epoch 15/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.7194 - accuracy: 0.7557\n",
            "Epoch 16/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.6824 - accuracy: 0.7722\n",
            "Epoch 17/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.6609 - accuracy: 0.7748\n",
            "Epoch 18/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.6153 - accuracy: 0.7943\n",
            "Epoch 19/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.6038 - accuracy: 0.7975\n",
            "Epoch 20/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.5584 - accuracy: 0.8134\n",
            "Epoch 21/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.5465 - accuracy: 0.8156\n",
            "Epoch 22/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.5150 - accuracy: 0.8261\n",
            "Epoch 23/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.4910 - accuracy: 0.8376\n",
            "Epoch 24/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.4813 - accuracy: 0.8386\n",
            "Epoch 25/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.4663 - accuracy: 0.8450\n",
            "Epoch 26/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.4338 - accuracy: 0.8554\n",
            "Epoch 27/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.4284 - accuracy: 0.8583\n",
            "Epoch 28/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.4132 - accuracy: 0.8648\n",
            "Epoch 29/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.3893 - accuracy: 0.8692\n",
            "Epoch 30/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.3832 - accuracy: 0.8727\n",
            "Epoch 31/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.3677 - accuracy: 0.8772\n",
            "Epoch 32/100\n",
            "350/350 [==============================] - 17s 50ms/step - loss: 0.3615 - accuracy: 0.8835\n",
            "Epoch 33/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.3438 - accuracy: 0.8840\n",
            "Epoch 34/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.3304 - accuracy: 0.8914\n",
            "Epoch 35/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.3244 - accuracy: 0.8945\n",
            "Epoch 36/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.3081 - accuracy: 0.8976\n",
            "Epoch 37/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.3106 - accuracy: 0.8979\n",
            "Epoch 38/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.2853 - accuracy: 0.9046\n",
            "Epoch 39/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.2867 - accuracy: 0.9056\n",
            "Epoch 40/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.2713 - accuracy: 0.9093\n",
            "Epoch 41/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.2525 - accuracy: 0.9176\n",
            "Epoch 42/100\n",
            "350/350 [==============================] - 19s 53ms/step - loss: 0.2509 - accuracy: 0.9167\n",
            "Epoch 43/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.2518 - accuracy: 0.9160\n",
            "Epoch 44/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.2398 - accuracy: 0.9201\n",
            "Epoch 45/100\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.2339 - accuracy: 0.9222\n",
            "Epoch 46/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.2235 - accuracy: 0.9258\n",
            "Epoch 47/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.2151 - accuracy: 0.9297\n",
            "Epoch 48/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.2116 - accuracy: 0.9310\n",
            "Epoch 49/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.2122 - accuracy: 0.9304\n",
            "Epoch 50/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.2048 - accuracy: 0.9329\n",
            "Epoch 51/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.2035 - accuracy: 0.9321\n",
            "Epoch 52/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.2020 - accuracy: 0.9317\n",
            "Epoch 53/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.1937 - accuracy: 0.9364\n",
            "Epoch 54/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1799 - accuracy: 0.9403\n",
            "Epoch 55/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1819 - accuracy: 0.9410\n",
            "Epoch 56/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1753 - accuracy: 0.9427\n",
            "Epoch 57/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1805 - accuracy: 0.9395\n",
            "Epoch 58/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1700 - accuracy: 0.9434\n",
            "Epoch 59/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.1770 - accuracy: 0.9402\n",
            "Epoch 60/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.1573 - accuracy: 0.9465\n",
            "Epoch 61/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1564 - accuracy: 0.9488\n",
            "Epoch 62/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1567 - accuracy: 0.9502\n",
            "Epoch 63/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.1474 - accuracy: 0.9504\n",
            "Epoch 64/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1547 - accuracy: 0.9496\n",
            "Epoch 65/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.1430 - accuracy: 0.9532\n",
            "Epoch 66/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1377 - accuracy: 0.9538\n",
            "Epoch 67/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1404 - accuracy: 0.9535\n",
            "Epoch 68/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1495 - accuracy: 0.9478\n",
            "Epoch 69/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1374 - accuracy: 0.9558\n",
            "Epoch 70/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1392 - accuracy: 0.9535\n",
            "Epoch 71/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1353 - accuracy: 0.9556\n",
            "Epoch 72/100\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.1255 - accuracy: 0.9574\n",
            "Epoch 73/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1205 - accuracy: 0.9590\n",
            "Epoch 74/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1218 - accuracy: 0.9596\n",
            "Epoch 75/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1167 - accuracy: 0.9614\n",
            "Epoch 76/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1332 - accuracy: 0.9553\n",
            "Epoch 77/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1214 - accuracy: 0.9608\n",
            "Epoch 78/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.1238 - accuracy: 0.9591\n",
            "Epoch 79/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.1085 - accuracy: 0.9632\n",
            "Epoch 80/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0806 - accuracy: 0.9750\n",
            "Epoch 81/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0786 - accuracy: 0.9753\n",
            "Epoch 82/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0598 - accuracy: 0.9819\n",
            "Epoch 83/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0660 - accuracy: 0.9800\n",
            "Epoch 84/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.0625 - accuracy: 0.9808\n",
            "Epoch 85/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0578 - accuracy: 0.9826\n",
            "Epoch 86/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0598 - accuracy: 0.9813\n",
            "Epoch 87/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0552 - accuracy: 0.9835\n",
            "Epoch 88/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0534 - accuracy: 0.9831\n",
            "Epoch 89/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0500 - accuracy: 0.9850\n",
            "Epoch 90/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0507 - accuracy: 0.9854\n",
            "Epoch 91/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0502 - accuracy: 0.9857\n",
            "Epoch 92/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.0464 - accuracy: 0.9869\n",
            "Epoch 93/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.0461 - accuracy: 0.9865\n",
            "Epoch 94/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0447 - accuracy: 0.9875\n",
            "Epoch 95/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0465 - accuracy: 0.9865\n",
            "Epoch 96/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0437 - accuracy: 0.9883\n",
            "Epoch 97/100\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 0.0449 - accuracy: 0.9865\n",
            "Epoch 98/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0420 - accuracy: 0.9880\n",
            "Epoch 99/100\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.0421 - accuracy: 0.9877\n",
            "Epoch 100/100\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.0394 - accuracy: 0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31bc5a9f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU9v_7wACtT1"
      },
      "source": [
        "from keras_preprocessing.image import array_to_img\n",
        "f = x_test[1][:][:][:]\n",
        "f = array_to_img(f)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "4TFiLz2cGFKb",
        "outputId": "ae8f5cd2-eab5-4321-84d5-7e29ed7a476b"
      },
      "source": [
        "f"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F30D0292850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67wk3NduCvPQ"
      },
      "source": [
        "y = x_test[0]\n",
        "y = y.reshape(1,32,32,3)\n",
        "r = np.argmax(AlexNet.predict(x_test), axis=-1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLmw7nMRDzoP",
        "outputId": "9988e923-4d67-4986-d150-a003244ea9c3"
      },
      "source": [
        "r.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_ZJpXvHYKe",
        "outputId": "c3b00078-3185-4e6d-e98d-f8d7b93e46c6"
      },
      "source": [
        "r"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, ..., 5, 2, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}